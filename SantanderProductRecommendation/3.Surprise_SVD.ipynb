{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and load input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Tools\\Miniconda3\\envs\\py_3_6_5_keras\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "d:\\Tools\\Miniconda3\\envs\\py_3_6_5_keras\\lib\\site-packages\\odo\\backends\\pandas.py:102: FutureWarning: pandas.tslib is deprecated and will be removed in a future version.\n",
      "You can access NaTType as type(pandas.NaT)\n",
      "  @convert.register((pd.Timestamp, pd.Timedelta), (pd.tslib.NaTType, type(None)))\n"
     ]
    }
   ],
   "source": [
    "from surprise import Reader, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import *\n",
    "from pathlib import Path\n",
    "import gc\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import log_loss\n",
    "import blaze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataframe.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Tools\\Miniconda3\\envs\\py_3_6_5_keras\\lib\\site-packages\\blaze\\compute\\pandas.py:792: UserWarning: Counting the elements of a dask object can be slow.\n",
      "  warnings.warn(\"Counting the elements of a dask object can be slow.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving dataframe to file.....\n"
     ]
    }
   ],
   "source": [
    "# csv_file = Path('Data/surprise_subset_train.csv')\n",
    "# csv_data = blaze.Data('Data/surprise_train.csv')\n",
    "# print('Loading dataframe.....')\n",
    "# query = csv_data[csv_data['Status_Dt'].isin(['2015-05-28', '2016-04-28', '2016-05-28'])]\n",
    "# train = pd.DataFrame.from_records(query, columns=query.fields)\n",
    "\n",
    "# print('Saving dataframe to file.....')\n",
    "# surprise_cols = ['Cust_ID', 'Product_ID', 'Rating', 'Status_Dt']\n",
    "# train = pd.read_csv(csv_file, usecols = surprise_cols)\n",
    "# train.drop(train[train.Rating.isnull()].index, inplace=True)\n",
    "# train.to_csv('Data/surprise_subset_train.csv', index=False)\n",
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.drop(train[train.Status_Dt == '2015-04-28'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cust_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Status_Dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1375586</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1375586</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1375586</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1375586</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1375586</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-05-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Cust_ID  Product_ID  Rating   Status_Dt\n",
       "24  1375586           0     0.0  2015-05-28\n",
       "25  1375586           1     0.0  2015-05-28\n",
       "26  1375586           2     1.0  2015-05-28\n",
       "27  1375586           3     0.0  2015-05-28\n",
       "28  1375586           4     0.0  2015-05-28"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train.to_csv('Data/surprise_subset_train.csv', index=False)\n",
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data from Data\\surprise_subset_train.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cust_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Status_Dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1375586</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1375586</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1375586</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1375586</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1375586</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-05-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cust_ID  Product_ID  Rating   Status_Dt\n",
       "0  1375586           0     0.0  2015-05-28\n",
       "1  1375586           1     0.0  2015-05-28\n",
       "2  1375586           2     1.0  2015-05-28\n",
       "3  1375586           3     0.0  2015-05-28\n",
       "4  1375586           4     0.0  2015-05-28"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = Path('Data/surprise_train.csv')\n",
    "if not csv_file.is_file():\n",
    "    print ('Creating Surprise Library Compliant File....')\n",
    "    use_cols = ['Status_Dt', 'Cust_ID', 'Savings_Acct', 'Guarantees', 'Cur_Acct',\\\n",
    "           'Derivative_Acct', 'Payroll_Acct', 'Junior_Acct', 'Mas_Particular_Acct', 'Particular_Acct',  \\\n",
    "            'Particular_Plus_Acct', 'Short_Term_Deposits', 'Med_Term_Deposits', 'Long_Term_Deposits', 'e-Acct', 'Funds', \\\n",
    "            'Mortgage', 'Pension1', 'Loans', 'Taxes', 'Credit_Card', 'Securities', 'Home_Acct', 'Payroll', 'Pension2', \\\n",
    "               'Direct_Debit']\n",
    "    train = pd.read_csv('Data/cleaned_train_ver2.csv', usecols = use_cols)\n",
    "    create_surprise_lib_compliant_file(train, csv_file)\n",
    "    del train\n",
    "    gc.collect()\n",
    "csv_file = Path('Data/surprise_subset_train.csv')\n",
    "print('Loading train data from {}'.format(csv_file))\n",
    "#I was running into memory issues so saved a subset of the file containing data\n",
    "# from April to May 2015 & 2016\n",
    "# csv_data = blaze.Data('Data/surprise_train.csv')\n",
    "# # query = csv_data[csv_data['a'] > csv_data['b']]\n",
    "# query = csv_data[csv_data['Status_Dt'].isin(['2015-04-28', '2015-05-28', '2016-04-28', '2016-05-28'])]\n",
    "# train = pd.DataFrame.from_records(query, columns=query.fields)\n",
    "\n",
    "# surprise_cols = ['Cust_ID', 'Product_ID', 'Rating', 'Status_Dt']\n",
    "# train = pd.read_csv(csv_file, usecols = surprise_cols)\n",
    "# train.drop(train[train.Rating.isnull()].index, inplace=True)\n",
    "# train.to_csv('Data/surprise_subset_train.csv', index=False)\n",
    "# train.head()\n",
    "surprise_cols = ['Cust_ID', 'Product_ID', 'Rating', 'Status_Dt']\n",
    "train = pd.read_csv(csv_file, usecols = surprise_cols)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cust_ID       0\n",
       "Product_ID    0\n",
       "Rating        0\n",
       "Status_Dt     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Mths_Since_2015\"] = train[\"Status_Dt\"].map(date_to_int).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016-05-28    22354872\n",
       "2016-04-28    22278576\n",
       "2015-05-28    15161358\n",
       "Name: Status_Dt, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Status_Dt.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_ids = train[train.Status_Dt == '2016-05-28']['Cust_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_ids = np.unique(cust_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use only 500000 cust_ids to train\n",
    "cust_ids = cust_ids[0:500000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset = train[train.Cust_ID.isin(cust_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "301"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33165974, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_subset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Train into Train and Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21165974, 5), (12000000, 5))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split train into train and validation set\n",
    "test_date = '2016-05-28'\n",
    "test_date_mths_since_2015 = date_to_int(test_date)\n",
    "train_df = train_subset[train_subset.Mths_Since_2015 < test_date_mths_since_2015]\n",
    "test_df = train_subset[train_subset.Mths_Since_2015 == test_date_mths_since_2015]\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_subset\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform input train dataset into a format compliant with Surprise Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is to specify how to read the dataframe.\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "\n",
    "# create the traindata from the dataframe...\n",
    "train_data = Dataset.load_from_df(train_df[['Cust_ID', 'Product_ID', 'Rating']], reader)\n",
    "\n",
    "# build the trainset from traindata to be compliant with surprise library's dataset format\n",
    "trainset = train_data.build_full_trainset() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_df will no longer be needed\n",
    "del train_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(935046, 0, 0.0), (935046, 1, 0.0), (935046, 2, 1.0)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset = list(zip(test_df.Cust_ID.values, test_df.Product_ID.values, test_df.Rating.values))\n",
    "testset[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratings(predictions):\n",
    "    actual = np.array([pred.r_ui for pred in predictions])\n",
    "    pred = np.array([pred.est for pred in predictions])\n",
    "    \n",
    "    return actual, pred\n",
    "\n",
    "def get_errors(predictions, print_them=False):\n",
    "\n",
    "    actual, pred = get_ratings(predictions)\n",
    "    error = log_loss(actual, pred, eps=1e-15, labels=[0,1])\n",
    "    return error\n",
    "    \n",
    "def run_surprise(algo, trainset, testset, verbose=True): \n",
    "    '''\n",
    "        return train_dict, test_dict\n",
    "    \n",
    "        It returns two dictionaries, one for train and the other is for test\n",
    "        Each of them have 3 key-value pairs, which specify ''rmse'', ''mape'', and ''predicted ratings''.\n",
    "    '''\n",
    "    start = datetime.now()\n",
    "    # dictionaries that stores metrics for train and test..\n",
    "    train = dict()\n",
    "    test = dict()\n",
    "    \n",
    "    # train the algorithm with the trainset\n",
    "    st = datetime.now()\n",
    "    print('Training the model...')\n",
    "    algo.fit(trainset)\n",
    "    print('Done. time taken : {} \\n'.format(datetime.now()-st))\n",
    "    \n",
    "    # ---------------- Evaluating train data--------------------#\n",
    "    st = datetime.now()\n",
    "    print('Evaluating the model with train data..')\n",
    "    # get the train predictions (list of prediction class inside Surprise)\n",
    "    build_testset = trainset.build_testset()\n",
    "    \n",
    "    train_preds = algo.test(build_testset)\n",
    "    \n",
    "    print('Train preds are {}'.format(train_preds))\n",
    "    # get predicted ratings from the train predictions..\n",
    "    train_actual_ratings, train_pred_ratings = get_ratings(train_preds)\n",
    "    \n",
    "    # get 'log_loss from the train predictions.\n",
    "    train_log_loss = get_errors(train_preds)\n",
    "    print('time taken : {}'.format(datetime.now()-st))\n",
    "    \n",
    "    if verbose:\n",
    "        print('-'*15)\n",
    "        print('Train Data')\n",
    "        print('-'*15)\n",
    "        print(\"LogLoss : {}\".format(train_log_loss))\n",
    "    \n",
    "    #store them in the train dictionary\n",
    "    if verbose:\n",
    "        print('adding train results in the dictionary..')\n",
    "    train['log_loss'] = train_log_loss\n",
    "    train['predictions'] = train_pred_ratings\n",
    "    \n",
    "    #------------ Evaluating Test data---------------#\n",
    "    st = datetime.now()\n",
    "    print('\\nEvaluating for test data...')\n",
    "    # get the predictions( list of prediction classes) of test data\n",
    "    test_preds = algo.test(testset)\n",
    "    # get the predicted ratings from the list of predictions\n",
    "    test_actual_ratings, test_pred_ratings = get_ratings(test_preds)\n",
    "    # get error metrics from the predicted and actual ratings\n",
    "    test_log_loss = get_errors(test_preds)\n",
    "    print('time taken : {}'.format(datetime.now()-st))\n",
    "    \n",
    "    if verbose:\n",
    "        print('-'*15)\n",
    "        print('Test Data')\n",
    "        print('-'*15)\n",
    "        print(\"LogLoss : {}\".format(test_log_loss))\n",
    "    # store them in test dictionary\n",
    "    if verbose:\n",
    "        print('storing the test results in test dictionary...')\n",
    "    test['log_loss'] = test_log_loss\n",
    "    test['predictions'] = test_pred_ratings\n",
    "    \n",
    "    print('\\n'+'-'*45)\n",
    "    print('Total time taken to run this algorithm :', datetime.now() - start)\n",
    "    \n",
    "    # return two dictionaries train and test\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({}, {})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products =  ['Savings_Acct', 'Guarantees', 'Cur_Acct', 'Derivative_Acct', 'Payroll_Acct', 'Junior_Acct', \\\n",
    "             'Mas_Particular_Acct', 'Particular_Acct', 'Particular_Plus_Acct', 'Short_Term_Deposits', \\\n",
    "            'Med_Term_Deposits', 'Long_Term_Deposits', 'e-Acct', 'Funds', 'Mortgage', 'Pension1', 'Loans', 'Taxes', \\\n",
    "             'Credit_Card', 'Securities', 'Home_Acct', 'Payroll', 'Pension2', 'Direct_Debit']\n",
    "models_evaluation_train = dict()\n",
    "models_evaluation_test = dict()\n",
    "\n",
    "models_evaluation_train, models_evaluation_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import BaselineOnly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Estimating biases using sgd...\n",
      "Done. time taken : 0:01:53.582650 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:56:58.243653\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "LogLoss : 0.3571407485363766\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:09:31.325906\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "LogLoss : 0.029859884499144507\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 1:08:23.310751\n"
     ]
    }
   ],
   "source": [
    "# Specify options to compute user and item biases\n",
    "bsl_options = {'method': 'sgd',\n",
    "               'learning_rate': .001\n",
    "               }\n",
    "bsl_algo = BaselineOnly(bsl_options=bsl_options)\n",
    "# run this algorithm.., It will return the train and test results..\n",
    "bsl_train_results, bsl_test_results = run_surprise(bsl_algo, trainset, testset, verbose=True)\n",
    "# train_preds = run_surprise(bsl_algo, trainset, testset, verbose=True)\n",
    "\n",
    "# Just store these error metrics in our models_evaluation datastructure\n",
    "models_evaluation_train['bsl_algo'] = bsl_train_results \n",
    "models_evaluation_test['bsl_algo'] = bsl_test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Matrix Factorization Techniques </h1>\n",
    "<h2> SVD Matrix Factorization User Product interactions </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "Done. time taken : 0:16:49.960005 \n",
      "\n",
      "Evaluating the model with train data..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken : 0:04:16.251591\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "LogLoss : 0.38150360771575476\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:03:42.971633\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "LogLoss : 0.057762452544384744\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:24:49.230125\n"
     ]
    }
   ],
   "source": [
    "# initialize the model\n",
    "n_factors=100 # decrease the dimensionality to 100. q_i and p_u will be of 100 dimensions. This is a hyperparameter.\n",
    "svd = SVD(n_factors=n_factors, biased=True, random_state=15, verbose=True)\n",
    "svd_train_results, svd_test_results = run_surprise(svd, trainset, testset, verbose=True)\n",
    "\n",
    "# Just store these error metrics in our models_evaluation datastructure\n",
    "models_evaluation_train['svd'] = svd_train_results \n",
    "models_evaluation_test['svd'] = svd_test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> SVD Matrix Factorization with implicit feedback from user ( user buying habits ) </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVDpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      " processing epoch 0\n",
      " processing epoch 1\n",
      " processing epoch 2\n",
      " processing epoch 3\n",
      " processing epoch 4\n",
      " processing epoch 5\n",
      " processing epoch 6\n",
      " processing epoch 7\n",
      " processing epoch 8\n",
      " processing epoch 9\n",
      " processing epoch 10\n",
      " processing epoch 11\n",
      " processing epoch 12\n",
      " processing epoch 13\n",
      " processing epoch 14\n",
      " processing epoch 15\n",
      " processing epoch 16\n",
      " processing epoch 17\n",
      " processing epoch 18\n",
      " processing epoch 19\n",
      "Done. time taken : 5:23:23.401136 \n",
      "\n",
      "Evaluating the model with train data..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken : 0:16:31.618370\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "LogLoss : 0.37011362952789095\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n"
     ]
    }
   ],
   "source": [
    "# initialize the model\n",
    "svdpp = SVDpp(n_factors=50, random_state=15, verbose=True)\n",
    "svdpp_train_results, svdpp_test_results = run_surprise(svdpp, trainset, testset, verbose=True)\n",
    "\n",
    "# Just store these error metrics in our models_evaluation datastructure\n",
    "models_evaluation_train['svdpp'] = svdpp_train_results \n",
    "models_evaluation_test['svdpp'] = svdpp_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_3_6_5_keras",
   "language": "python",
   "name": "py_3_6_5_keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
